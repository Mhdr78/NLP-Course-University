{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc828ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee8f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    '''\n",
    "    Inputs: \n",
    "        z: output scores from the hidden layer\n",
    "    Outputs: \n",
    "        yhat: prediction (estimate of y)\n",
    "    '''\n",
    "    ### START CODE HERE (Replace instances of 'None' with your own code) ###\n",
    "    # Calculate yhat (softmax)\n",
    "    yhat = np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "    ### END CODE HERE ###\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4936948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    # relu functon\n",
    "    return np.maximum(z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eca9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(words, word2Ind):\n",
    "    idx = []\n",
    "    for word in words:\n",
    "        idx = idx + [word2Ind[word]]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb29799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_idx_with_frequency(context_words, word2Ind):\n",
    "    freq_dict = defaultdict(int)\n",
    "    for word in context_words:\n",
    "        freq_dict[word] += 1\n",
    "    idxs = get_idx(context_words, word2Ind)\n",
    "    packed = []\n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        freq = freq_dict[context_words[i]]\n",
    "        packed.append((idx, freq))\n",
    "    return packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b5efbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, word2Ind, V, C):\n",
    "    i = C\n",
    "    while True:\n",
    "        y = np.zeros(V)\n",
    "        x = np.zeros(V)\n",
    "        center_word = data[i]\n",
    "        # one-hot vector for center word\n",
    "        y[word2Ind[center_word]] = 1\n",
    "        \n",
    "        context_words = data[(i - C) : i] + data[(i + 1) : (i + C + 1)]\n",
    "        num_ctx_words = len(context_words)\n",
    "        for idx, freq in pack_idx_with_frequency(context_words, word2Ind):\n",
    "            # one-hot vector for context words\n",
    "            x[idx] = freq / num_ctx_words\n",
    "        yield x, y\n",
    "        # sliding window to the right\n",
    "        i += 1\n",
    "        if i >= len(data):\n",
    "            print(\"i is being set to 0\")\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab0a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, word2Ind, V, C, batch_size):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for x, y in get_vectors(data, word2Ind, V, C):\n",
    "        while len(batch_x) < batch_size:\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "        else:\n",
    "            yield np.array(batch_x).T, np.array(batch_y).T\n",
    "            batch_x = []\n",
    "            batch_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57669335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca(data, n_components=2):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        data: of dimension (m,n) where each row corresponds to a word vector\n",
    "        n_components: Number of components you want to keep.\n",
    "    Output: \n",
    "        X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
    "    pass in: data as 2D NumPy array\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = data.shape\n",
    "\n",
    "    # mean center the data\n",
    "    data -= data.mean(axis=0)\n",
    "    # calculate the covariance matrix\n",
    "    R = np.cov(data, rowvar=False)\n",
    "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
    "    # use 'eigh' rather than 'eig' since R is symmetric,\n",
    "    # the performance gain is substantial\n",
    "    evals, evecs = linalg.eigh(R)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    # this returns the corresponding indices of evals and evecs\n",
    "    idx = np.argsort(evals)[::-1]\n",
    "\n",
    "    evecs = evecs[:, idx]\n",
    "    # sort eigenvectors according to same index\n",
    "    evals = evals[idx]\n",
    "    # select the first n eigenvectors (n is desired dimension\n",
    "    # of rescaled data array, or dims_rescaled_data)\n",
    "    evecs = evecs[:, :n_components]\n",
    "    ### END CODE HERE ###\n",
    "    return np.dot(evecs.T, data.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118aedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        data: the data you want to pull from\n",
    "    Output:\n",
    "        word2Ind: returns dictionary mapping the word to its index\n",
    "        Ind2Word: returns dictionary mapping the index to its word\n",
    "    \"\"\"\n",
    "    \n",
    "    # words = nltk.word_tokenize(data)\n",
    "    words = sorted(list(set(data)))\n",
    "    n = len(words)\n",
    "    idx = 0\n",
    "    # return these correctly\n",
    "    word2Ind = {}\n",
    "    Ind2word = {}\n",
    "    for k in words:\n",
    "        word2Ind[k] = idx\n",
    "        Ind2word[idx] = k\n",
    "        idx += 1\n",
    "    return word2Ind, Ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cf09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v, w):\n",
    "    d = linalg.norm(v-w)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f49d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v, w):\n",
    "    c = np.dot(v,w) / (linalg.norm(v)*linalg.norm(w))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826f974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
